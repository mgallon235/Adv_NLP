{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1571446-71d6-482a-921f-ff928aa2fff7",
   "metadata": {},
   "source": [
    "# Setting Up the Problem\n",
    "\n",
    "#### Objective: Understand and establish the baseline for your chosen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac018b8a-0b53-46b2-b91a-252984c73f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import support_functions\n",
    "from support_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9121702b-d562-407e-afb3-9a582ee3ad56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikelgallo/anaconda3/envs/text_2/lib/python3.12/site-packages/datasets/load.py:1461: FutureWarning: The repository for carblacac/twitter-sentiment-analysis contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/carblacac/twitter-sentiment-analysis\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset(\"carblacac/twitter-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc46d8fc-29bb-41d2-86e8-fcac4d8e8e73",
   "metadata": {},
   "source": [
    "### Characteristics of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73993a8-3a67-4a56-8317-93ef13228920",
   "metadata": {},
   "source": [
    "**TSATC: Twitter Sentiment Analysis Training Corpus**   \n",
    "Original DATASET contains 1,578,627 classified tweets (1 for positive and 0 for negative sentiment).\n",
    "\n",
    "Our dataset has already been randomly sampled, cleaned, and split into training and testing sets. Both positive and negative classes are well balanced within each subset, and the training subset has been further divided into an 80% training set and a 20% validation set.\n",
    "\n",
    "Source: https://github.com/cblancac/SentimentAnalysisBert/blob/main/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b7d6ee-8603-45c1-9733-4a4435227853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'feeling'],\n",
       "        num_rows: 119988\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'feeling'],\n",
       "        num_rows: 29997\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'feeling'],\n",
       "        num_rows: 61998\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Defining train, validation and test sets\n",
    "train_data = df['train']['text']\n",
    "train_labels = df['train']['feeling']\n",
    "\n",
    "validation_data = df['validation']['text']\n",
    "validation_labels = df['validation']['feeling']\n",
    "\n",
    "test_data = df['test']['text']\n",
    "test_labels = df['test']['feeling']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876139fc",
   "metadata": {},
   "source": [
    "### Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a64eb5d1-0e3e-4149-ae74-63afa5297e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "   class  count    perc\n",
      "0      1  60019  0.5002\n",
      "1      0  59969  0.4998\n",
      "validation\n",
      "   class  count    perc\n",
      "0      0  15050  0.5017\n",
      "1      1  14947  0.4983\n",
      "test\n",
      "   class  count    perc\n",
      "0      1  31029  0.5005\n",
      "1      0  30969  0.4995\n"
     ]
    }
   ],
   "source": [
    "## Class balance of our datasets\n",
    "print('train')\n",
    "class_prop(train_labels)\n",
    "print('validation')\n",
    "class_prop(validation_labels)\n",
    "print('test')\n",
    "class_prop(test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
