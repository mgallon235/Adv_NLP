{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1571446-71d6-482a-921f-ff928aa2fff7",
   "metadata": {},
   "source": [
    "# Setting Up the Problem\n",
    "\n",
    "#### Objective: Understand and establish the baseline for your chosen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac018b8a-0b53-46b2-b91a-252984c73f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import support_functions\n",
    "from support_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9121702b-d562-407e-afb3-9a582ee3ad56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikelgallo/anaconda3/envs/text_2/lib/python3.12/site-packages/datasets/load.py:1461: FutureWarning: The repository for carblacac/twitter-sentiment-analysis contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/carblacac/twitter-sentiment-analysis\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset(\"carblacac/twitter-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc46d8fc-29bb-41d2-86e8-fcac4d8e8e73",
   "metadata": {},
   "source": [
    "### Characteristics of the dataset\n",
    "\n",
    "**b. Dataset Description (0.5 points): Provide a brief overview of your dataset, including size, class distribution, and any peculiar characteristics. Include basic descriptive statistics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73993a8-3a67-4a56-8317-93ef13228920",
   "metadata": {},
   "source": [
    "**TSATC: Twitter Sentiment Analysis Training Corpus**   \n",
    "Original DATASET contains 1,578,627 classified tweets (1 for positive and 0 for negative sentiment).\n",
    "\n",
    "Our dataset has already been randomly sampled, cleaned, and split into training and testing sets. Both positive and negative classes are well balanced within each subset, and the training subset has been further divided into an 80% training set and a 20% validation set.\n",
    "\n",
    "Source: https://github.com/cblancac/SentimentAnalysisBert/blob/main/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b7d6ee-8603-45c1-9733-4a4435227853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'feeling'],\n",
       "        num_rows: 119988\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'feeling'],\n",
       "        num_rows: 29997\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'feeling'],\n",
       "        num_rows: 61998\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Defining train, validation and test sets\n",
    "train_data = df['train']['text']\n",
    "train_labels = df['train']['feeling']\n",
    "\n",
    "validation_data = df['validation']['text']\n",
    "validation_labels = df['validation']['feeling']\n",
    "\n",
    "test_data = df['test']['text']\n",
    "test_labels = df['test']['feeling']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e6a7ac",
   "metadata": {},
   "source": [
    "### Dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac3c887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Split [TRAIN, TEST]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SET</th>\n",
       "      <th>ROWS</th>\n",
       "      <th>SPLIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>149985</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST</td>\n",
       "      <td>61998</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>211983</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SET    ROWS  SPLIT\n",
       "0  TRAIN  149985  0.708\n",
       "1   TEST   61998  0.292\n",
       "2  TOTAL  211983  1.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Split [train, validation]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SET</th>\n",
       "      <th>ROWS</th>\n",
       "      <th>SPLIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>119988</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validation</td>\n",
       "      <td>29997</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>149985</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SET    ROWS  SPLIT\n",
       "0       train  119988    0.8\n",
       "1  validation   29997    0.2\n",
       "2       TRAIN  149985    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_rows = len(train_labels) + len(test_labels) + len(validation_labels)\n",
    "# Calculate train size including validation\n",
    "Train_size = len(train_labels) + len(validation_labels)\n",
    "# Calculate Summary\n",
    "summary_df = pd.DataFrame({'SET': ['TRAIN','TEST', 'TOTAL'], 'ROWS': [Train_size, len(test_labels), total_rows], 'SPLIT': [Train_size/total_rows, len(test_labels)/total_rows,total_rows/total_rows]})\n",
    "print('Dataset Split [TRAIN, TEST]')\n",
    "display(summary_df.round(3))\n",
    "\n",
    "## TRAIN SPLIT\n",
    "summary_df_train = pd.DataFrame({'SET': ['train','validation', 'TRAIN'], 'ROWS': [len(train_labels), len(validation_labels), Train_size], 'SPLIT': [len(train_labels)/Train_size, len(validation_labels)/Train_size,Train_size/Train_size]})\n",
    "print('TRAIN Split [train, validation]')\n",
    "display(summary_df_train.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876139fc",
   "metadata": {},
   "source": [
    "### Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a64eb5d1-0e3e-4149-ae74-63afa5297e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "   class  count    perc\n",
      "0      1  60019  0.5002\n",
      "1      0  59969  0.4998\n",
      "validation\n",
      "   class  count    perc\n",
      "0      0  15050  0.5017\n",
      "1      1  14947  0.4983\n",
      "test\n",
      "   class  count    perc\n",
      "0      1  31029  0.5005\n",
      "1      0  30969  0.4995\n"
     ]
    }
   ],
   "source": [
    "## Class balance of our datasets\n",
    "print('train')\n",
    "class_prop(train_labels)\n",
    "print('validation')\n",
    "class_prop(validation_labels)\n",
    "print('test')\n",
    "class_prop(test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
